\chapter{Análisis de Identificadores}

\section{Identificadores}
Formalmente, un identificador t es una secuencia de caracteres c0, c1, …, cn, dondel el caracter ci representa una letra, un dígito o un caracter especial. Hard words, soft words. COMPLETAR

Ver Rilling y Klemola - Identifying comprehension bottlenecks using program slicing and cognitive complexity metrics.

Ver Caprille y Tonella - Reestructuring program identifier names.

\subsection{Identificadores concisos y consistentes}
Cada lenguaje de programación plantea sus propios estilos de codificación, así como también convenciones para los nombres de los identificadores. Sin embargo, éstas suelen enfocarse solamente en la sintaxis, dejando de lado uno de los aspectos de mayor interés, el cual se corresponde a la semántica de los nombres empleados. La importancia en la definición de nombres de calidad radica en la influencia que los mismos tienen durante la comprensión de programas, y como consecuencia, en la calidad y productividad a lo largo del ciclo de vida del software. La ofuscación de código a través de la conversión de identificadores a secuencias aleatorias de caracteres es un claro ejemplo del impacto que tienen los nombres en el proceso de comprensión.

DeiBenbock y Pizka definen, a través de un \textbf{modelo formal}, una estrategia para la creación de nombres bien formados. En ésta se incluyen dos reglas, las cuales permiten un nombramiento conciso y consistente de variables, funciones y clases \cite{DeiBenbockPizka05}. La premisa sobre la que basan estas reglas viene dada por la correlación de identificadores con el conjunto de conceptos que son utilizados en un programa.

\subsubsection{Conceptos nombrados}
Primero, se establece a \textit{C} como el conjunto de todos los conceptos relevantes dentro de un determinado alcance (un componente de un programa, el dominio de la aplicación o una organización). A su vez, se define un concepto como una unidad con un significado asociado en términos de comportamiento o propiedades. Además, se modelan todos los nombres posibles y se denotan por \textit{N}, junto con la asignación de nombres a conceptos como una relación formal $R \subseteq N \times C$.

\subsubsection{Regla 1: Consistencia}
Del lenguaje natural heredamos dos tipos de incosistencias: homónimos y sinónimos.

Un \textbf{homónimo} es aquella palabra que se escribe o pronuncia igual que otra, pero tiene diferente significado, y su definición formal viene dada por: un nombre $n \in N$ es llamado homónimo sí y solo sí $|C_n| > 1$ donde $C_n = \{ c \in C : (n,c) \in R\}$.

A su vez, un \textbf{sinónimo} es aquella palabra que, si bien se escribe de forma diferente, refiere al mismo concepto que otra. La definición formal se establece como: dos nombres $s,n \in N$ son sinónimos sí y sólo sí $C_s \cap C_n \neq 0$.

Ante la ausencia de homónimos, el daño de los sinónimos es limitado ya que siempre apuntan a un único concepto. Sin embargo, incrementan innecesariamente el dominio \textit{N} y la relación \textit{R}, y por consiguiente un aumento en el esfuerzo para comprender el lenguaje utilizado. La presencia de homónimos y sinónimos tiene un impacto negativo importante ya que para cada identificador \textit{n}, el desarrollador tiene que considerar todos los conceptos en
\\
\\$M_n = \bigcup_{e \in n} C_e$
\\
\\donde $S_n$ es el conjunto de todos los nombres sinónimos a \textit{n} (incluyendo a \textit{n} mismo).

Dadas estas condiciones, podemos decir que un sistema de nombres \textit{C}, \textit{N} y \textit{R} es \textit{consistente} sí y sólo sí $R \subseteq N \times C$ es una relación bijectiva. Por lo tanto, se define como:
\\$n : C \rightarrow N$
\\$n(c) = \mbox{nombre único del concepto} \ c$.

\subsubsection{Regla 2: Conciso}
Para definir \textit{conciseness} debemos introducir el orden parcial $\sqsubset$ para el conjunto de conceptos \textit{C}, de acuerdo a su nivel de abstracción.

Dado el conjunto \textit{P}, el cual contiene elementos del programa que son identificados como unidades a través de un nombre simbólico, y dada \textit{i}, que representa el mapeo de los elementos del programa con sus identificadores.
\\$i : P \rightarrow N$
\\$i(p) = \mbox{identificador de} \ p$.

Además, dado $\lbrack c \rbrack$, el cual denota la semántica en el sentido del significado de un concepto $c \in C$. De la misma manera, $\lbrack p \rbrack$ denota la semántica de un elemento del programa \textit{p}.

Establecidas estas condiciones, definimos el problema de \textit{conciseness} en dos pasos. Primero se requiere la \textit{correcta} identificación, y luego la validación de \textit{conciseness}.

\paragraph{Definición: correctitud}
Sea $p \in P$ un elemento del programa y $c \in C$ el concepto que implementa, tal que $\lbrack p \rbrack = \lbrack c \rbrack$. El identificador \textit{i(p)} es \textit{correcto} sí y solo sí ocurre lo siguiente:
\\$i(p) \in \lbrace n(c') : c' \in C \land c' \sqsupseteq c \rbrace$
\\Esto significa que el identificador de un elemento del programa \textit{p} que manifiesta el concepto \textit{c} debe corresponderse al nombre de \textit{c} o a una generalización del mismo. Sin embargo, a veces ocurre que de alguna manera, los nombres de los identificadores son correctos pero no lo suficientemente consisos. Para contrarestar esta situación, se agrega el siguiente requerimiento:

\paragraph{Definición: conciso}
Sea $p \in P$ un elemento del programa y $c \in C$ el concepto que implementa, tal que $\lbrack p \rbrack = \lbrack c \rbrack$. El identificador \textit{i(p)} para el elemento \textit{p} del programa es \textit{conciso} sí y sólo sí lo siguiente es verdad:
\\$i(p) = n(c)$
\\Esta definición requiere que un identificador tenga exactamente el mismo nombre del concepto que representa.

\subsubsection{Consistencia y Conciseness sintácticas}
El modelo formal descrito por DeiBenbock y Pizka requiere que exista un mapeo entre los elementos del dominio de conceptos y los identificadores. Sin esta definición, se hace imposible la relación entre los dos conjuntos. Ahora bien, para nuevos programas, la construcción de este mapeo puede hacerse al mismo tiempo que el desarrollo con un mínimo costo extra. Sin embargo, para aquellos proyectos existentes, el costo puede ser demasiado. Para contrarestar esta limitación, se plantea el uso de la \textit{consistencia y conciseness sintática}, en donde sólo se considera la construcción sintática de los identificadores \cite{LawrieFeildBinkley06}.

El enfoque se basa en la contención de identificadores. Se dice que un identificador está contenido dentro de otro si todas sus \textit{soft words} están presentes, en el mismo orden, en el identificador contenedor. Cuando un identificador está contenido dentro de otro, una de dos posibles violaciones han ocurrido. Por un lado, puede que haya un solo concepto asociado a dos identificadores, lo que implica una violación al requerimiento respecto a los sinónimos en la consistencia; por otro, que los dos identificadores refieran a diferentes conceptos. En este caso, no se cumpliría la regla de nombres concisos. (- ver figuras-)

\paragraph{Definición: Conciseness y Consistencia de sinónimos sintática}
Sea el identificador $id_1$ una secuencia de soft words $sw_1 sw_2 ... sw_n1$. Los identificadores $id_1$ e $id_2$ no cumplen el \textit{requerimiento sobre sinónimos en la consistencia sintáctia} si $id_2$ incluye la secuencia de soft words $w_1 w_2 ... sw_1 sw_2 ... sw_n1 ... w_n2$. Además, $id_1$ falla el \textit{requerimiento sobre la concisenss sintáctica} si existe un tercer identificador $id_3$ que incluya la secuencia de soft words $u_1 u_2 ... sw_1 sw_2 ... sw_n1 ... u_n3$.

\section{División}
El objetivo de un algoritmo divisor de identificadores es tomar un identificador como entrada, y generar como salida
 una lista de sub-elementos que que particionan al identificador original. Estos sub-elementos pueden palabras de diccionario, las cuales tienen un significado obvio; abreviaturas, las cuales representan una sola palabra del diccionario; o acrónimos, los cuales representan varias palabras de diccionario [Hill Binkley Lawrie. An empirical study of identifier splitting techniques].

VER: mixed-case/same-case splitting problem.

Algunas de las principales técnicas para la división de identificadores son:
Greedy. Esta técnica utiliza un diccionario, una lista de abreviaturas conocidas y una lista de finalización (stop-list), la cual incluye identificadores predefinidos, liberías, funciones y nombres de variables comunes, y letras individuales. Después de retornar cada hard word encontrada en alguna de las tres listas de palabras como una soft word simple, el resto de las hard words se consideran para división. Por lo tanto, el enfoque Greedy se basa en un diccionario predefinido de palabras y abreviaturas, donde las divisiones están basadas en que la palabra se encuentre en alguna de las listas, prefieriendo palabras m’as largas.
Samurai. Este algoritmo se basa en la premisa que strings que componen identifcadores multi-palabras en un determinado programa, son frecuentemente utilizados en algún otro lugar, tanto del mismo programa como de otros. Por lo tanto, la frecuencia es el principal elemento tenido en cuenta a la hora de dividir identificadores. La división se realiza de izquierda a derecha, “dampening the score for shorter words”.
GenTest. El algoritmo de GenTest tiene su fuerte en los términos same-case (focus on the same-case splitting problem). Dado un término same-case, esta técnica genera primero todas las posibles divisiones (dados que los identificadores son relativamente cortos, el potencialmente exponencial número de divisiones es manejable en la práctica), para luego scorear cada división, eligiendo la de mayor resultado. La función de scoring se basa en la premisa de que soft words expandidas deberían encontrarse co-ubicadas en la documentación o texto general (similarity metric).
DTW. Este approach se basa en la observación de que los programadores construyen nuevos identificadores aplicando un conjunto de transformaciones a las palabras, como por ejemplo quitar todas las vocales o quitar uno o más caracteres. Utilizando un diccionario que contenga palabras y términos pertenecientes a una ontología superior, al dominio de la aplicación o ambos, el objetivo es identificar “a near optimal” matching entre los substrings del indentificador y las palabras en el diccionario. El identificador es considerado una señal de significado desconocido, descrita por un vector. Cada palabra del diccionario es utilizada como una segunda (conocida) señal  descrita también por un “feature vector”. El algoritmo realiza un dynamic time warping (DTW) de los dos vectores para encontrar el matcheo óptimo. El “time warp” de la búsqueda permite que las longitudes de los dos vectores difieran y se permitan abreviaturas en el dominio de la división (splitting domain). El match óptimo se obtiene de computar las distancias locales y luego elegir los matcheos que minimicen la distancia total utilizando programación dinámica. (Buscar PAPER).
INTT. El enfoque INTT busca realizar un división más acertada (accurate) que las técnicas previas al utilizar una heurística especializada para manejar identificadores con dígitos, opuesto a la separación de los digitos del resto del texto en etapas tempranas del proceso de división. La principal modificación es reemplazar greedy por dos algoritmos, greedy y greedier, el cual puede tokenizar same-case identifiers sin el requerimiento de que comience o termine con una palabra conocida. Se utiliza una lista de acrónimos que contienen dígitos. (Buscar PAPER).

Para el presente informe, sólo son de interés - y por lo tanto explicadas en mayor detalle - las primeras tres técnicas listadas anteriormente.

\subsection{Algoritmo Greedy}
\subsection{Algoritmo Samurai}
\subsection{Algoritmo GenTest}

\section{Expansión}
